{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bJGo7VtV_eAT"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KcMRWKs-_6Sr"
   },
   "outputs": [],
   "source": [
    "### Constants\n",
    "DATA_PATH = \"./dataset_newone/train_data\" # path to the dataset\n",
    "LABEL_PATH = './media/labels_no0.csv' # path to the labels csv file\n",
    "RESULT_PATH = \"./dataset_newone.p\" # path to the labels csv file\n",
    "BATCH_SIZE_VAL = 50 # size of batches during training\n",
    "STEPS_X_EPOCH = 2000 # number of steps per epoch\n",
    "N_EPOCHS = 1 # number of epochs for training\n",
    "IMG_DIM = (32,32,3) # dimensions of the images (height, width, channels)\n",
    "TEST_DATA = 0.2 # proportion of the data to use for testing (1000 images split will 200)\n",
    "VAL_DATA = 0.2 # proportion of training data to use for validation (1000 images 20% of remaining 800 will be 160 for validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w7wKzaSU_-9a"
   },
   "outputs": [],
   "source": [
    "### Functions\n",
    "def grayscale(img):\n",
    "\t\"\"\"function to convert the image to grayscale\"\"\"\n",
    "\tif len(img.shape) == 2: # if image is already grayscale\n",
    "\t\treturn img # return it as is\n",
    "\telse:\n",
    "\t\timg = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) # convert to grayscale\n",
    "\t\treturn img\n",
    "\n",
    "def equalize(img):\n",
    "\t\"\"\"function to equalize the histogram for contrast adjustment\"\"\"\n",
    "\timg = img.astype(numpy.uint8) # ensure the image is 8-bit grayscale\n",
    "\timg = cv2.equalizeHist(img) # apply histogram equalization\n",
    "\treturn img\n",
    "\n",
    "def preprocessing(img):\n",
    "\t\"\"\"function to preprocess the image\"\"\"\n",
    "\timg = grayscale(img) # convert to grayscale\n",
    "\timg = equalize(img) # equalize histogram\n",
    "\timg = img / 255 # normalize pixel values to the range [0, 1] instead of [0, 255]\n",
    "\treturn img\n",
    "\n",
    "def t_sign_model(n_classes):\n",
    "\t\"\"\"funtion to define the CNN model\"\"\"\n",
    "\tn_kernels = 60 # number of kernels\n",
    "\tkernel_size_5x5 = (5, 5) # size of the kernels (5x5)\n",
    "\tkernel_size_3x3 = (3, 3) # size of the second kernel (3x3)\n",
    "\tpool_size = (2, 2) # size of the pooling window (2x2): reduces img size by half to prevent overfitting\n",
    "\tn_nodes = 500 # number of nodes in the fully connected layer\n",
    "\n",
    "\t# initialize the model\n",
    "\tmodel = Sequential()\n",
    "\n",
    "\t# First convolutional block (add more conv layers = less features but more accurate)\n",
    "\tmodel.add((Conv2D(n_kernels, kernel_size_5x5, input_shape=(IMG_DIM[0], IMG_DIM[1], 1), activation='relu')))\n",
    "\tmodel.add((Conv2D(n_kernels, kernel_size_5x5, activation='relu'))) # 2nd conv layer\n",
    "\tmodel.add(MaxPooling2D(pool_size=pool_size)) # max pooling layer\n",
    "\n",
    "\t# Second convolutional block\n",
    "\tmodel.add((Conv2D(n_kernels // 2, kernel_size_3x3, activation='relu'))) # 3rd conv layer with smaller kernel size\n",
    "\tmodel.add((Conv2D(n_kernels // 2, kernel_size_3x3, activation='relu'))) # 4th conv layer\n",
    "\tmodel.add(MaxPooling2D(pool_size=pool_size)) # max pooling layer\n",
    "\tmodel.add(Dropout(0.5)) # dropout layer to prevent overfitting\n",
    "\n",
    "\t# Fully connected layers\n",
    "\tmodel.add(Flatten()) # flatten the output for the fully connected layer\n",
    "\tmodel.add(Dense(n_nodes, activation='relu')) # fully connected layer with ReLU activation\n",
    "\tmodel.add(Dropout(0.5)) # dropout layer for regularization\n",
    "\tmodel.add(Dense(n_classes, activation='softmax')) # output layer with softmax for multi-class classification\n",
    "\n",
    "\t# compile the model with Adam optimizer and categorical cross-entropy loss\n",
    "\tmodel.compile(Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1344532,
     "status": "ok",
     "timestamp": 1728723882569,
     "user": {
      "displayName": "Matteo Aprile",
      "userId": "01782337209846835788"
     },
     "user_tz": -120
    },
    "id": "eP0EZ4P2AByj",
    "outputId": "abf3e0a8-3a0b-4170-aa27-4cffb2716aec"
   },
   "outputs": [],
   "source": [
    "# importing of the Images\n",
    "class_id = 0 # index for classes\n",
    "images = [] # list for image data\n",
    "class_labels = [] # list for class labels\n",
    "classes = os.listdir(DATA_PATH) # list all folders (classes)\n",
    "labels = pandas.read_csv(LABEL_PATH) # read the labels csv file\n",
    "n_classes = len(labels) # total number of classes\n",
    "print(\"Total Classes Detected:\", n_classes)\n",
    "\n",
    "# test that there are all folders\n",
    "print(\"Classes Detected\")\n",
    "for x in range (0, n_classes):\n",
    "    if os.listdir(DATA_PATH+\"/\"+str(class_id)): # list images in class folder\n",
    "        print(DATA_PATH+\"/\"+str(class_id)) # print class index\n",
    "    else:\n",
    "        print(\"NO <------>\" + DATA_PATH+\"/\"+str(class_id))\n",
    "    class_id += 1\n",
    "\n",
    "class_id = 0\n",
    "# load the images\n",
    "print(\"Importing Classes.....\")\n",
    "for x in range (0, n_classes):\n",
    "    imgs = os.listdir(DATA_PATH+\"/\"+str(class_id)) # list images in class folder\n",
    "\n",
    "    for y in imgs: # loop through each image\n",
    "        # Skip hidden files like .DS_Store\n",
    "        if y.startswith('.'):\n",
    "            continue\n",
    "\n",
    "        cur_img = cv2.imread(DATA_PATH+\"/\"+str(class_id)+\"/\"+y) # read image\n",
    "\n",
    "        # Check if image was loaded successfully\n",
    "        if cur_img is not None:\n",
    "            cur_img = cv2.resize(cur_img, (IMG_DIM[0], IMG_DIM[1])) # resize to IMG_DIM\n",
    "            images.append(cur_img) # add image to the list\n",
    "            class_labels.append(class_id) # add class label\n",
    "        else:\n",
    "            print(f\"Failed to load image: {DATA_PATH}/{class_id}/{y}\")\n",
    "\n",
    "    print(class_id, end =\" \") # print class index\n",
    "    class_id += 1\n",
    "print(\" \")\n",
    "\n",
    "images = numpy.array(images) # convert list of images to numpy array\n",
    "class_labels = numpy.array(class_labels) # convert list of class labels to numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 250,
     "status": "ok",
     "timestamp": 1728723882810,
     "user": {
      "displayName": "Matteo Aprile",
      "userId": "01782337209846835788"
     },
     "user_tz": -120
    },
    "id": "ql2KVUwdAI7a",
    "outputId": "ebc19699-f0a5-452e-9903-1e53165eb651"
   },
   "outputs": [],
   "source": [
    "# split Data\n",
    "    # X_train = array of images to train\n",
    "    # y_train = corresponding class IDs\n",
    "    # X_test = array of images to test\n",
    "    # y_test = corresponding class IDs\n",
    "\n",
    "# split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, class_labels, test_size=TEST_DATA)\n",
    "# further split training data into training and validation sets\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=VAL_DATA)\n",
    "\n",
    "\n",
    "# print the shapes of the datasets\n",
    "print(\"Data Shapes\")\n",
    "print(\"Train\", X_train.shape, y_train.shape) # print training data shape\n",
    "print(\"Validation\", X_validation.shape, y_validation.shape) # print validation data shape\n",
    "print(\"Test\", X_test.shape, y_test.shape) # print test data shape\n",
    "\n",
    "# check if the number of images matches the number of labels for each dataset\n",
    "print(f\"X_train: {X_train.shape[0]}, y_train: {y_train.shape[0]}\")\n",
    "assert(X_train.shape[0] == y_train.shape[0]), \"The number of images is not equal to the number of labels in the training set\"\n",
    "print(f\"X_validation: {X_validation.shape[0]}, y_validation: {y_validation.shape[0]}\")\n",
    "assert(X_validation.shape[0] == y_validation.shape[0]), \"The number of images is not equal to the number of labels in the validation set\"\n",
    "print(f\"X_test: {X_test.shape[0]}, y_test: {y_test.shape[0]}\")\n",
    "assert(X_test.shape[0] == y_test.shape[0]), \"The number of images is not equal to the number of labels in the test set\"\n",
    "\n",
    "# check if the image dimensions are correct\n",
    "assert(X_train.shape[1:] == (IMG_DIM)), \"The dimensions of the training images are wrong\"\n",
    "assert(X_validation.shape[1:] == (IMG_DIM)), \"The dimensions of the validation images are wrong\"\n",
    "assert(X_test.shape[1:] == (IMG_DIM)), \"The dimensions of the test images are wrong\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 17573,
     "status": "ok",
     "timestamp": 1728723900378,
     "user": {
      "displayName": "Matteo Aprile",
      "userId": "01782337209846835788"
     },
     "user_tz": -120
    },
    "id": "FFWzEMYBALVe",
    "outputId": "c3480b8b-ee3a-449a-8237-4c2e52eca47e"
   },
   "outputs": [],
   "source": [
    "# read the label data from csv file\n",
    "print(\"data shape \", labels.shape, type(labels))\n",
    "\n",
    "# display some sample images from each class\n",
    "\n",
    "sample_x_class = [] # list for the number of samples per class\n",
    "n_cols = 5 # number of columns for displaying images\n",
    "fig, axs = plt.subplots(nrows=n_classes, ncols=n_cols, figsize=(5, 300)) # create subplots\n",
    "fig.tight_layout() # adjust layout to prevent overlap\n",
    "\n",
    "# loop through and display images\n",
    "for i in range(n_cols):\n",
    "    for j, row in labels.iterrows(): # iterate over rows in the labels\n",
    "        x_selected = X_train[y_train == j] # select images from the current class\n",
    "        axs[j][i].imshow(x_selected[random.randint(0, len(x_selected) - 1), :, :], cmap=plt.get_cmap(\"gray\")) # display a random image\n",
    "        axs[j][i].axis(\"off\") # hide axis (for cleaner display)\n",
    "\n",
    "        if i == 2:\n",
    "            axs[j][i].set_title(str(j) + \"-\" + row[\"Name\"]) # set title to class label\n",
    "            sample_x_class.append(len(x_selected)) # add the number of samples for this class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 448
    },
    "executionInfo": {
     "elapsed": 413,
     "status": "ok",
     "timestamp": 1728723900778,
     "user": {
      "displayName": "Matteo Aprile",
      "userId": "01782337209846835788"
     },
     "user_tz": -120
    },
    "id": "NnWs1aKSARQI",
    "outputId": "96de2e00-5045-4028-fa09-a3b8cf2e400c"
   },
   "outputs": [],
   "source": [
    "# plot the distribution of training dataset\n",
    "print(sample_x_class)\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.bar(range(0, n_classes), sample_x_class) # create a bar chart for sample distribution\n",
    "plt.title(\"Distribution of the training dataset\")\n",
    "plt.xlabel(\"Class number\")\n",
    "plt.ylabel(\"Number of images\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jrPLdRYlAR17"
   },
   "outputs": [],
   "source": [
    "# preprocess training, validation, and test sets\n",
    "X_train = numpy.array(list(map(preprocessing, X_train)))\n",
    "X_validation = numpy.array(list(map(preprocessing, X_validation)))\n",
    "X_test = numpy.array(list(map(preprocessing, X_test)))\n",
    "\n",
    "# add a depth of 1 to the images\n",
    "\n",
    "# reshape the data to add a depth of 1 (grayscale images have only one channel)\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1)\n",
    "X_validation = X_validation.reshape(X_validation.shape[0], X_validation.shape[1], X_validation.shape[2], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "executionInfo": {
     "elapsed": 1294,
     "status": "ok",
     "timestamp": 1728723902461,
     "user": {
      "displayName": "Matteo Aprile",
      "userId": "01782337209846835788"
     },
     "user_tz": -120
    },
    "id": "DftL5Jp8AUJr",
    "outputId": "8552c600-cf50-4094-cd9e-f3ca24d11f86"
   },
   "outputs": [],
   "source": [
    "# augmentation of images to make the model more robust\n",
    "\n",
    "# create an image data generator for augmenting the training data\n",
    "img_gen = ImageDataGenerator(width_shift_range=0.1, # randomly shift images horizontally by 10%\n",
    "                            height_shift_range=0.1, # randomly shift images vertically by 10%\n",
    "                            zoom_range=0.2, # randomly zoom in or out\n",
    "                            shear_range=0.1, # randomly shear the images\n",
    "                            rotation_range=10) # randomly rotate images by up to 10 degrees\n",
    "img_gen.fit(X_train) # fit the generator on the training data\n",
    "batches = img_gen.flow(X_train, y_train, batch_size=20) # generate augmented images\n",
    "X_batch, y_batch = next(batches) # get the next batch\n",
    "\n",
    "# display some augmented images\n",
    "fig, axs = plt.subplots(1, 15, figsize=(20, 5))\n",
    "fig.tight_layout()\n",
    "for i in range(15):\n",
    "    axs[i].imshow(X_batch[i].reshape(IMG_DIM[0], IMG_DIM[1])) # reshape to 32x32 and display\n",
    "    axs[i].axis('off') # hide axis (for cleaner display)\n",
    "plt.show()\n",
    "\n",
    "# convert labels to one-hot encoded format\n",
    "y_train = to_categorical(y_train, n_classes)\n",
    "y_validation = to_categorical(y_validation, n_classes)\n",
    "y_test = to_categorical(y_test, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "executionInfo": {
     "elapsed": 244,
     "status": "error",
     "timestamp": 1729453095723,
     "user": {
      "displayName": "Matteo Aprile",
      "userId": "01782337209846835788"
     },
     "user_tz": -120
    },
    "id": "a6o5n9SnAXYS",
    "outputId": "b5876c8b-03f4-481c-d554-0fedb197084a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 279/2000\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:47\u001b[0m 97ms/step - accuracy: 0.0729 - loss: 3.4072"
     ]
    }
   ],
   "source": [
    "# build and train the model\n",
    "model = t_sign_model(n_classes)\n",
    "print(model.summary())\n",
    "\n",
    "history = model.fit(\n",
    "    img_gen.flow(X_train, y_train, batch_size=BATCH_SIZE_VAL), # train the model using data augmentation\n",
    "    steps_per_epoch=STEPS_X_EPOCH, # number of steps per epoch\n",
    "    epochs=N_EPOCHS, # number of epochs\n",
    "    validation_data=(X_validation, y_validation), # validation data\n",
    "    shuffle=1 # shuffle data during training\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 43066,
     "status": "ok",
     "timestamp": 1728733351481,
     "user": {
      "displayName": "Matteo Aprile",
      "userId": "01782337209846835788"
     },
     "user_tz": -120
    },
    "id": "l_tCZYXbiNDS",
    "outputId": "7961ee39-e769-4d85-f770-43f0d8e7e65b"
   },
   "outputs": [],
   "source": [
    "# plot the training and validation loss\n",
    "plt.figure(1)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.legend(['training', 'validation'])\n",
    "plt.title('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "\n",
    "# plot the training and validation accuracy\n",
    "plt.figure(2)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.legend(['training', 'validation'])\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()\n",
    "\n",
    "# Get the last values of validation loss\n",
    "last_val_loss = history.history['val_loss'][-1]\n",
    "print(f'Last Validation Loss: {last_val_loss}')\n",
    "\n",
    "# Get the last values of validation accuracy\n",
    "last_val_accuracy = history.history['val_accuracy'][-1]\n",
    "print(f'Last Validation Accuracy: {last_val_accuracy}')\n",
    "\n",
    "\n",
    "# evaluate the model on the test set\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test Score:', score[0]) # print test loss\n",
    "print('Test Accuracy:', score[1]) # print test accuracy\n",
    "\n",
    "# save the trained model\n",
    "pickle_out = open(\"xxxxxx.p\", \"wb\")\n",
    "pickle.dump(model, pickle_out) # serialize and save the model\n",
    "pickle_out.close()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPvcIoa5kIAOxUUJoB7Tjb0",
   "mount_file_id": "1Rmm1rqJNyNn938q86W4vKKSvM-JULaQQ",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
